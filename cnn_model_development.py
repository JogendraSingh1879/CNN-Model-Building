# -*- coding: utf-8 -*-
"""CNN- Model Development.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kBZKTRPDosG1hj8Z1A9eHTZ2Uu9W-hKL

## CNN
"""

# Installing tensorflow
!pip install tensorflow

# Importing importing libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D
from sklearn.metrics import confusion_matrix, classification_report

#extracting the mnist dataset

(X_train, y_train), (X_test, y_test) = mnist.load_data()

# printing the shape
print('Shape of X train :', X_train.shape)
print('Shape of y train :', y_train.shape)
print('Shape of X test :', X_test.shape)
print('Shape of y test :', y_test.shape)

np.unique(y_train)

# Visualize some samples
plt.figure(figsize = (12, 9))
for i in range(10):
  plt.subplot(5, 5, i+1)
  plt.imshow(X_train[i], cmap = 'gray')
  plt.title(y_train[i])
  plt.axis('off')
  plt.title(y_train[i])
plt.show()

# Building the CNN Architecture
model = Sequential([
    Conv2D(32, (3, 3), activation = 'relu', input_shape = (28, 28, 1)),
    MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation = 'relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(128, activation = 'relu'),
    Dropout(0.2),
    Dense(10, activation = 'softmax')
])

# Compiling the model
model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# Summary
model.summary()

# Training the model
history = model.fit(X_train, y_train, epochs = 10, validation_split = 0.2)

# Model Evaluation
test_loss, test_acc = model.evaluate(X_test, y_test)
print('Test Accuracy :', test_acc)
print('Test Loss :', test_loss)

# Plotting training and validation accuracy
plt.figure(figsize = (12, 5))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label = 'Training Accuracy')
plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label = 'Training Loss')
plt.plot(history.history['val_loss'], label = 'Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.show()

# Confusion Matrix
y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis = 1)
cm = confusion_matrix(y_test, y_pred_classes)
plt.figure(figsize = (12, 9))
sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()